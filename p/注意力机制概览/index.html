<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="一、背景 注意力机制可有效提高模型对特征的提取能力，进而提高模型精度。本文首先对经典的三种注意力学习方法进行介绍，后结合自己一点点浅薄认知，对">
<title>注意力机制概览</title>

<link rel='canonical' href='https://wakingupdelta.github.io/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/'>

<link rel="stylesheet" href="/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css"><meta property='og:title' content="注意力机制概览">
<meta property='og:description' content="一、背景 注意力机制可有效提高模型对特征的提取能力，进而提高模型精度。本文首先对经典的三种注意力学习方法进行介绍，后结合自己一点点浅薄认知，对">
<meta property='og:url' content='https://wakingupdelta.github.io/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/'>
<meta property='og:site_name' content='想起床的方差'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2024-05-12T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2024-05-12T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="注意力机制概览">
<meta name="twitter:description" content="一、背景 注意力机制可有效提高模型对特征的提取能力，进而提高模型精度。本文首先对经典的三种注意力学习方法进行介绍，后结合自己一点点浅薄认知，对">
    <link rel="shortcut icon" href="/favicon.ico" />

  


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu002516796a89100b6bac501e69a8f35d_5680_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">想起床的方差</a></h1>
            <h2 class="site-description">要多想，要多想，要多想</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://juejin.cn/user/1819016667072378'
                        target="_blank"
                        title="JueJin"
                        rel="me"
                    >
                        
                        
                            <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-brand-juejin"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M2 12l10 7.422l10 -7.422" /><path d="M7 9l5 4l5 -4" /><path d="M11 6l1 .8l1 -.8l-1 -.8z" /></svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>主页</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>暗色模式</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" >
                深度学习
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/">注意力机制概览</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2024-05-12</time>
            </div>
        

        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="一背景">一、背景
</h1><p>注意力机制可有效提高模型对特征的提取能力，进而提高模型精度。本文首先对经典的三种注意力学习方法进行介绍，后结合自己一点点浅薄认知，对注意力机制后续的改进方向进行归纳，希望对大家能有帮助</p>
<h1 id="二前置知识">二、前置知识
</h1><h2 id="21-通道注意力">2.1 通道注意力
</h2><img src="image-20240903143439161.png" alt="image-20240903143439161" style="zoom:67%;" />
对特征图进行全局平均池化，后经过两层全连接层，最后使用Sigmoid输出0-1之间的权重
<h2 id="22-空间注意力">2.2 空间注意力
</h2><img src="image-20240903143451755.png" alt="image-20240903143451755" style="zoom:67%;" />
将特征图进行压缩，得到空间方向上的权重图
<h2 id="23-self-attention">2.3 self-attention
</h2><img src="image-20240903143502737.png" alt="image-20240903143502737" style="zoom:67%;" />
<p>这里借助了Non-local Neural Networks中的一张图。self-attention本质上是一种空间注意机制，如上图所示，需要求解一个[THW, THW]的矩阵，该矩阵中的每一行，表示原特征图中的一点与其余点的关系</p>
<h1 id="三各种改进版本">三、各种改进版本
</h1><p>将改进的注意力机制主要分为四类</p>
<ul>
<li>跨特征：构建不同的特征表达，后进行融合</li>
<li>分组：对特征图按通道分组后，再使用注意力机制</li>
<li>self-attention：本质上，self-attention就是一系列矩阵运算，对运算过程中的某些步骤进行优化</li>
<li>空间+通道：很自然的想法，同时使用两种注意力机制</li>
</ul>
<h2 id="31-跨特征">3.1 跨特征
</h2><h4 id="311-bisenet">3.1.1 BiSeNet
</h4><img src="image-20240903143515154.png" alt="image-20240903143515154" style="zoom:67%;" />
对不同层次的特征使用通道注意力机制进行融合。这应该属于应用创新，没有构建新的注意力机制，而是将老的注意力机制应用到特征融合方向
<h4 id="312-sknet">3.1.2 SKNet
</h4><p><img src="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143528059.png"
	width="1257"
	height="359"
	srcset="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143528059_hu4188395624d6c6de293fd145c8a93efd_185865_480x0_resize_box_3.png 480w, /p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143528059_hu4188395624d6c6de293fd145c8a93efd_185865_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="image-20240903143528059"
	
	
		class="gallery-image" 
		data-flex-grow="350"
		data-flex-basis="840px"
	
></p>
<p>使用不同感受野卷积核构建多分支特征，将这些特征 add 后计算不同分支的同道注意力系数，后沿着通道方向进行加权求和</p>
<h2 id="32-分组">3.2 分组
</h2><h3 id="321-sgnet">3.2.1 SGNet
</h3><p><img src="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143537682.png"
	width="1252"
	height="426"
	srcset="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143537682_hud065ca2fd1dda1682e5e65c580ff9f53_319318_480x0_resize_box_3.png 480w, /p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143537682_hud065ca2fd1dda1682e5e65c580ff9f53_319318_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="image-20240903143537682"
	
	
		class="gallery-image" 
		data-flex-grow="293"
		data-flex-basis="705px"
	
></p>
<p>对每个组，先计算向量x的平均值（全局平均池化），后将利用该向量对特征图沿着通道 方向加权求和得到 空间注意力，再归一化，后经sigmoid函数输出</p>
<h3 id="322-sanet">3.2.2 SANet
</h3><p><img src="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143548571.png"
	width="1256"
	height="347"
	srcset="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143548571_hube3e2276944c2386941e589284b66220_149550_480x0_resize_box_3.png 480w, /p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143548571_hube3e2276944c2386941e589284b66220_149550_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="image-20240903143548571"
	
	
		class="gallery-image" 
		data-flex-grow="361"
		data-flex-basis="868px"
	
></p>
<p>将特征沿着通道分组，对每一组，再分成 空间注意力 和 通道注意力。对空间注意力，使用Group normalization实现。将分组结果进行拼接，后使用类似ShufflfleNet v2的方法进行channel shuffle</p>
<h2 id="33-self-attention">3.3 Self Attention
</h2><h3 id="331-non-local-attention">3.3.1 non local attention
</h3><img src="image-20240903143603023.png" alt="image-20240903143603023" style="zoom:67%;" />
<p>定义了不同形式计算向量相似性的函数，提出self attention是non local attention 的特例</p>
<h3 id="332-gcnet">3.3.2 GCNet
</h3><p><img src="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143615249.png"
	width="1260"
	height="424"
	srcset="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143615249_hu1aa83e91a93954a70623cd5a573c4860_237508_480x0_resize_box_3.png 480w, /p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143615249_hu1aa83e91a93954a70623cd5a573c4860_237508_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="image-20240903143615249"
	
	
		class="gallery-image" 
		data-flex-grow="297"
		data-flex-basis="713px"
	
></p>
<p>指出non local attention不同位置的attention map基本一致，只计算Cx1x1的特征图</p>
<h3 id="333-dual-attention">3.3.3 dual attention
</h3><img src="image-20240903143636442.png" alt="image-20240903143636442" style="zoom: 50%;" />
<p>并联non local attention 和 GCnet</p>
<h2 id="34-空间通道">3.4 空间+通道
</h2><h3 id="341-bam">3.4.1 BAM
</h3><p><img src="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143651005.png"
	width="1259"
	height="445"
	srcset="/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143651005_hu64b85001a552aa50dce13d8f55530e40_190059_480x0_resize_box_3.png 480w, /p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A6%82%E8%A7%88/image-20240903143651005_hu64b85001a552aa50dce13d8f55530e40_190059_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="image-20240903143651005"
	
	
		class="gallery-image" 
		data-flex-grow="282"
		data-flex-basis="679px"
	
></p>
<p>并联，attention map先相加（利用了广播机制），后与原特征图相乘</p>
<h3 id="342-scse">3.4.2 scSE
</h3><img src="image-20240903143703961.png" alt="image-20240903143703961" style="zoom:50%;" />
<p>并联，attention map先各自相乘，后取最大值得到最终输出</p>
<h1 id="参考文献">参考文献
</h1><p><a class="link" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Changqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.pdf"  target="_blank" rel="noopener"
    >[1] BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</a></p>
<p><a class="link" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Selective_Kernel_Networks_CVPR_2019_paper.pdf"  target="_blank" rel="noopener"
    >[2] Selective Kernel Networks</a></p>
<p><a class="link" href="https://arxiv.org/pdf/1905.09646.pdf"  target="_blank" rel="noopener"
    >[3] Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks</a></p>
<p><a class="link" href="https://arxiv.org/pdf/2102.00240.pdf"  target="_blank" rel="noopener"
    >[4] SA-NET: SHUFFLE ATTENTION FOR DEEP CONVOLUTIONAL NEURAL NETWORKS</a></p>
<p><a class="link" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf"  target="_blank" rel="noopener"
    >[5] Non-local Neural Networks</a></p>
<p><a class="link" href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Cao_GCNet_Non-Local_Networks_Meet_Squeeze-Excitation_Networks_and_Beyond_ICCVW_2019_paper.pdf"  target="_blank" rel="noopener"
    >[6] GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></p>
<p><a class="link" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Fu_Dual_Attention_Network_for_Scene_Segmentation_CVPR_2019_paper.pdf"  target="_blank" rel="noopener"
    >[7] Dual Attention Network for Scene Segmentation</a></p>
<p><a class="link" href="https://arxiv.org/pdf/1807.06514.pdf"  target="_blank" rel="noopener"
    >[8] BAM: Bottleneck Attention Module</a></p>
<p><a class="link" href="https://arxiv.org/pdf/1808.08127.pdf"  target="_blank" rel="noopener"
    >[9] Recalibrating Fully Convolutional Networks with Spatial and Channel ‘Squeeze &amp; Excitation’ Blocks</a></p>

</section>


    <footer class="article-footer">
    

    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2024 想起床的方差
    </section>
    
    <section class="powerby">
        使用 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 构建 <br />
        主题 <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.26.0">Stack</a></b> 由 <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> 设计
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
